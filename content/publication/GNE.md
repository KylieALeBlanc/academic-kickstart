+++
title = "Gather-Narrow-Extract: A Framework for Studying Local Policy Variation Using Web-Scraping and Natural Language Processing"
abstract = "Education researchers have traditionally faced severe data limitations in studying local policy variation; administrative data sets capture only a fraction of districtsâ€™ policy decisions, and it can be expensive to collect more nuanced implementation data from teachers and leaders. Natural language processing and web-scraping techniques can help address these challenges by assisting researchers in locating and processing policy documents located online. School district policies and practices are commonly documented in student and staff manuals, school improvement plans, and meeting minutes that are posted for the public. This article introduces an end-to-end framework for collecting these sorts of policy documents and extracting structured policy data: The researcher gathers all potentially relevant documents from district websites, narrows the text corpus to spans of interest using a text classifier, and then extracts specific policy data using additional natural language processing techniques. Through this framework, a researcher can describe variation in policy implementation at the local level, aggregated across state- or nationwide populations even as policies evolve over time."
date = "2019-12-01"
image_preview = ""
math = false
publication = "**Kylie L. Anglin** (2019) Gather-Narrow-Extract: A Framework for Studying Local Policy Variation Using Web-Scraping and Natural Language Processing, *Journal of Research on Educational Effectiveness*, 12:4, 685-706, https://doi.org/10.1080/19345747.2019.1654576"
url_code = ""
url_dataset = ""
#url_pdf = "https://curry.virginia.edu/sites/default/files/uploads/epw/68_Framework_Local_Policy_Variation_updated_1.pdf"
url_project = ""
url_slides = ""
url_video = ""
draft = false
featured = true


# Tags and categories
# For example, use `tags = []` for no tags, or the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["web scraping", "nlp", "policy", "implementation"]
categories = []

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
[image]
  # Caption (optional)
  caption = ""

  # Focal point (optional)
  # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
  focal_point = ""
+++

